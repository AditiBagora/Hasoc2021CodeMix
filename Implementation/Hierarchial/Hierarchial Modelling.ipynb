{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hierarchial Modelling.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyORA3vKTzUju4pZeCvCLJ3z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"mXI2rqCVKng2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641632807057,"user_tz":-345,"elapsed":25651,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}},"outputId":"1e2132b5-1178-4233-d905-ec7b30ad037e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","% cd /content/drive/MyDrive/HASOC Project Folder/2021 Dataset/CodeMix Dataset/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/HASOC Project Folder/2021 Dataset/CodeMix Dataset\n"]}]},{"cell_type":"code","metadata":{"id":"iZeea8jHSDAR"},"source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-mW5GaPQLq9X"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.set_option('display.max_columns', None)  # or 1000\n","pd.set_option('display.max_rows', None)  # or 1000\n","pd.set_option('display.max_colwidth', None) "],"metadata":{"id":"M15bUo0w_pF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YHWlIN6Lym_"},"source":["from glob import glob\n","import re\n","import json\n","\n","train_directories = []\n","for i in glob(\"data/train/*/\"):\n","    for j in glob(i+'*/'):\n","        train_directories.append(j)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ga_oclqnMJ23"},"source":["data = []\n","for i in train_directories:\n","    with open(i+'data.json', encoding='utf-8') as f:\n","        data.append(json.load(f))\n","labels = []\n","for i in train_directories:\n","    with open(i+'labels.json', encoding='utf-8') as f:\n","        labels.append(json.load(f))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZeSyR8ZAQfG"},"source":["def p2_flatten(d, l):\n","\n","    flat_text = []\n","\n","    flat_text.append({\n","        \"post\": d['tweet'],\n","        \"context\":\"\",\n","        'text': \"\",\n","        'label': l[d['tweet_id']]\n","    })\n","\n","    for i in d['comments']:\n","\n","        flat_text.append({\n","            \"post\": d['tweet'],\n","            'context': i[\"tweet\"],\n","            'text': \"\",\n","            'label': l[i['tweet_id']]\n","        })\n","\n","        if 'replies' in i.keys():\n","            for j in i['replies']:\n","                previous_reply = \"\"\n","                flat_text.append({\n","                    \"post\": d['tweet'],\n","                    'context': i[\"tweet\"] + previous_reply,\n","                    'text': j['tweet'],\n","                    'label': l[j['tweet_id']]\n","                })\n","                previous_reply = previous_reply + \" [SEP] \"+ j[\"tweet\"]\n","\n","    return flat_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxNXAaKYAQfH"},"source":["data_label = []\n","\n","for i in range(len(labels)):\n","    for j in p2_flatten(data[i], labels[i]):\n","        data_label.append(j)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZ1hBU79AQfI"},"source":["df = pd.DataFrame(data_label, columns = data_label[0].keys(), index = None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[\"label\"] = df[\"label\"].map({\"HOF\":1,\"NONE\":0})"],"metadata":{"id":"5PViY6TwyNGY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_pickle(\"train_hierarchial.pkl\")"],"metadata":{"id":"4wRY4oz9C3yf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FQ9d2IjRtKo","executionInfo":{"status":"ok","timestamp":1641632902302,"user_tz":-345,"elapsed":420,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}},"outputId":"49c4247c-d658-4122-ab26-6ca65d36715a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2819 entries, 0 to 2818\n","Data columns (total 4 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   post     2819 non-null   object\n"," 1   context  2819 non-null   object\n"," 2   text     2819 non-null   object\n"," 3   label    2819 non-null   int64 \n","dtypes: int64(1), object(3)\n","memory usage: 88.2+ KB\n"]}]},{"cell_type":"code","source":["train = pd.read_pickle(\"train_hierarchial.pkl\")"],"metadata":{"id":"sEYaHlngrGOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"18iJrdbiBbRdyMkTWeHqsPKL13RDmOQoU"},"id":"teEvejYm2iV5","executionInfo":{"status":"ok","timestamp":1641632910010,"user_tz":-345,"elapsed":3101,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}},"outputId":"dcf6584c-9841-4b38-c4aa-8542c91232d2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["post,context, label = train.post.values, train.context, train.label"],"metadata":{"id":"-tktq9CtaRxU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#check for GPU access\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpFV-pMidiH4","executionInfo":{"status":"ok","timestamp":1641610761308,"user_tz":-345,"elapsed":6306,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}},"outputId":"146c58ed-7358-464c-9639-797c6a70d8dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No GPU available, using the CPU instead.\n"]}]},{"cell_type":"code","source":["!pip install transformers --quiet"],"metadata":{"id":"KDTnuo2vKq0M","executionInfo":{"status":"ok","timestamp":1641610769847,"user_tz":-345,"elapsed":8550,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"47da5b2d-470b-4c8a-d645-098642698962"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 3.4 MB 5.2 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 55.4 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 35.5 MB/s \n","\u001b[K     |████████████████████████████████| 3.3 MB 36.0 MB/s \n","\u001b[K     |████████████████████████████████| 61 kB 482 kB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["from transformers import BertModel\n","import torch\n","import torch.nn as nn\n","from transformers import BertTokenizer, BertModel\n","\n","class CustomBERTModel(nn.Module):\n","    def __init__(self):\n","          super(CustomBERTModel, self).__init__()\n","\n","          self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","          self.bert = BertModel.from_pretrained('bert-base-uncased')\n","         \n","          self.linear1 = nn.Linear(1536, 768)\n","          self.linear2 = nn.Linear(768, 300)\n","          self.linear3 = nn.Linear(1068, 768)\n","          self.linear4 = nn.Linear(768,2)\n","\n","    def bert_representations(self, sentence):\n","      input = self.tokenizer(sentence, return_tensors = \"pt\")\n","      outputs =  self.bert(**input)\n","      return outputs.last_hidden_state[:,0,:]\n","\n","    def concatenate(self, tensor1, tensor2):\n","      return torch.cat((tensor1, tensor2), 1)\n","      \n","    def forward(self, post, context, text, label, only_post = False, post_context=False):\n","\n","      if only_post:\n","        post = self.bert_representations(post)\n","        linear4_output = self.linear4(post)\n","\n","      elif post_context:\n","        post, context = self.bert_representations(post), self.bert_representations(context)\n","        post_context = self.concatenate(post, context)\n","        linear1_output = self.linear1(post_context)\n","        linear4_output = self.linear4(linear1_output)\n","\n","      else:\n","        post, context, text = self.bert_representations(post), self.bert_representations(context), self.bert_representations(text)\n","\n","        context_text = self.concatenate(context, text)\n","\n","        linear1_output = self.linear1(context_text)\n","\n","        linear2_output = self.linear2(linear1_output)\n","\n","        post_context_text = self.concatenate(post, linear2_output)\n","\n","        linear3_output = self.linear3(post_context_text)\n","\n","        linear4_output = self.linear4(linear3_output)\n","\n","      return linear4_output"],"metadata":{"id":"GrDBKDToXT3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = CustomBERTModel()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SESSD0_Ewj54","executionInfo":{"status":"ok","timestamp":1641611407691,"user_tz":-345,"elapsed":3338,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}},"outputId":"22c9e4cf-5d94-42db-a25c-d9ca636fa3fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aevqgxsLwcfF","executionInfo":{"status":"ok","timestamp":1641611407692,"user_tz":-345,"elapsed":9,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}},"outputId":"39f5fea3-0748-4e36-dba3-6205fd2beda5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The BERT model has 207 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","linear3.weight                                           (768, 1068)\n","linear3.bias                                                  (768,)\n","linear4.weight                                              (2, 768)\n","linear4.bias                                                    (2,)\n"]}]},{"cell_type":"code","source":["epochs = 4\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n","\n","\n","print(\"Training....\")\n","\n","for epoch in range(epochs):\n","    total_train_loss=0\n","\n","    print(\"==========Epochs:{}===========\".format(epoch)) \n","\n","    for post, context,text, label in zip(train[\"post\"], train[\"context\"], train[\"text\"], train[\"label\"]):\n","\n","      if context==\"\":\n","        logits = model.forward(post, context,text, label, only_post=True)\n","\n","      elif context!=\"\" and text==\"\":\n","        logits = model.forward(post, context,text, label,post_context=True)\n","\n","      else:\n","        logits = model.forward(post, context,text, label)\n","\n","      print(logits)\n","      optimizer.zero_grad() \n","\n","      one_hot = torch.zeros(1, 2)\n","      one_hot[0, label] = 1\n","        \n","      loss = criterion(logits, one_hot)\n","\n","      total_train_loss += loss\n"," \n","      loss.backward()\n","\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","      optimizer.step()\n","\n","    print(\"Training Loss: {}\".format((total_train_loss/len(df)).item()))\n","    print(\"=========================\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qMYqxSVFw0r4","outputId":"6ae5b80b-d96b-4bb9-9335-5e7dc66e9598","executionInfo":{"status":"ok","timestamp":1641611531300,"user_tz":-345,"elapsed":123612,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training....\n","==========Epochs:0===========\n","tensor([[0.4296, 0.0394]], grad_fn=<AddmmBackward0>)\n","tensor([[-0.0083, -0.2433]], grad_fn=<AddmmBackward0>)\n","tensor([[ 5.9600, -5.4087]], grad_fn=<AddmmBackward0>)\n","tensor([[-0.1721,  0.1087]], grad_fn=<AddmmBackward0>)\n","tensor([[-4.7218,  4.3171]], grad_fn=<AddmmBackward0>)\n","tensor([[-6.9588,  6.3769]], grad_fn=<AddmmBackward0>)\n","tensor([[ 2.9862, -3.0744]], grad_fn=<AddmmBackward0>)\n","tensor([[-0.9076,  0.7013]], grad_fn=<AddmmBackward0>)\n","tensor([[-4.0221,  3.5611]], grad_fn=<AddmmBackward0>)\n","tensor([[-1.5806,  1.2522]], grad_fn=<AddmmBackward0>)\n","0.008275897242128849\n","Training....\n","==========Epochs:1===========\n","tensor([[-0.8340,  0.5336]], grad_fn=<AddmmBackward0>)\n","tensor([[ 1.0934, -1.0150]], grad_fn=<AddmmBackward0>)\n","tensor([[ 8.3489, -7.7873]], grad_fn=<AddmmBackward0>)\n","tensor([[ 4.8184, -4.7326]], grad_fn=<AddmmBackward0>)\n","tensor([[ 1.1642, -1.2842]], grad_fn=<AddmmBackward0>)\n","tensor([[-5.1292,  4.5427]], grad_fn=<AddmmBackward0>)\n","tensor([[-6.3955,  5.7052]], grad_fn=<AddmmBackward0>)\n","tensor([[-6.9777,  6.2168]], grad_fn=<AddmmBackward0>)\n","tensor([[-7.1655,  6.3556]], grad_fn=<AddmmBackward0>)\n","tensor([[-5.0201,  4.3648]], grad_fn=<AddmmBackward0>)\n","0.010538214817643166\n","Training....\n","==========Epochs:2===========\n","tensor([[ 3.3161, -2.9781]], grad_fn=<AddmmBackward0>)\n","tensor([[-2.4163,  0.8839]], grad_fn=<AddmmBackward0>)\n","tensor([[-0.9599, -0.5047]], grad_fn=<AddmmBackward0>)\n","tensor([[-0.3045,  0.0196]], grad_fn=<AddmmBackward0>)\n","tensor([[-1.0342,  0.8094]], grad_fn=<AddmmBackward0>)\n","tensor([[-2.6585,  2.4559]], grad_fn=<AddmmBackward0>)\n","tensor([[-2.9867,  2.8043]], grad_fn=<AddmmBackward0>)\n","tensor([[-3.3233,  3.1482]], grad_fn=<AddmmBackward0>)\n","tensor([[-2.7889,  2.1694]], grad_fn=<AddmmBackward0>)\n","tensor([[-3.0691,  3.2439]], grad_fn=<AddmmBackward0>)\n","0.004257148131728172\n","Training....\n","==========Epochs:3===========\n","tensor([[ 1.4794, -1.0861]], grad_fn=<AddmmBackward0>)\n","tensor([[-1.7186,  1.1176]], grad_fn=<AddmmBackward0>)\n","tensor([[-0.1684, -0.4331]], grad_fn=<AddmmBackward0>)\n","tensor([[-3.9919,  3.6987]], grad_fn=<AddmmBackward0>)\n","tensor([[-3.9314,  3.6310]], grad_fn=<AddmmBackward0>)\n","tensor([[-3.8737,  3.5695]], grad_fn=<AddmmBackward0>)\n","tensor([[-3.3346,  2.9231]], grad_fn=<AddmmBackward0>)\n","tensor([[-2.8879,  2.3904]], grad_fn=<AddmmBackward0>)\n","tensor([[-2.5894,  2.0460]], grad_fn=<AddmmBackward0>)\n","tensor([[-1.8803,  1.1549]], grad_fn=<AddmmBackward0>)\n","0.003769239876419306\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"bLy2D1JAq31j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"CsDk4CgVq33o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testing Setup"],"metadata":{"id":"IZeFBkSkrnve"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Svhr05Lmq4Pr"},"source":["from glob import glob\n","import re\n","import json\n","\n","train_directories = []\n","for i in glob(\"test/*/\"):\n","    for j in glob(i+'*/'):\n","        train_directories.append(j)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zUDPWURvq4Pu"},"source":["data = []\n","for i in train_directories:\n","    with open(i+'data.json', encoding='utf-8') as f:\n","        data.append(json.load(f))\n","labels = []\n","for i in train_directories:\n","    with open(i+'labels.json', encoding='utf-8') as f:\n","        labels.append(json.load(f))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1VZtNkQq4Pv"},"source":["def p2_flatten(d, l):\n","\n","    flat_text = []\n","\n","    flat_text.append({\n","        \"post\": d['tweet'],\n","        \"context\":\"\",\n","        'text': \"\",\n","        'label': l[d['tweet_id']]\n","    })\n","\n","    for i in d['comments']:\n","\n","        flat_text.append({\n","            \"post\": d['tweet'],\n","            'context': i[\"tweet\"],\n","            'text': \"\",\n","            'label': l[i['tweet_id']]\n","        })\n","        if 'replies' in i.keys():\n","            for j in i['replies']:\n","                previous_reply = \"\"\n","                flat_text.append({\n","                    \"post\": d['tweet'],\n","                    'context': i[\"tweet\"] + previous_reply,\n","                    'text': j['tweet'],\n","                    'label': l[j['tweet_id']]\n","                })\n","                previous_reply = previous_reply + \" [SEP] \"+ j[\"tweet\"]\n","\n","    return flat_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"REN3BeEtq4Px"},"source":["data_label = []\n","\n","for i in range(len(labels)):\n","    for j in p2_flatten(data[i], labels[i]):\n","        data_label.append(j)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NL3Ew8aq4Py"},"source":["df = pd.DataFrame(data_label, columns = data_label[0].keys(), index = None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[\"label\"] = df[\"label\"].map({\"HOF\":1,\"NONE\":0})"],"metadata":{"id":"LeDZ6YRqq4Pz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBdKDpXwRya8","executionInfo":{"status":"ok","timestamp":1641632950382,"user_tz":-345,"elapsed":12,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}},"outputId":"7d37d1a3-d08d-47ac-c7dd-d7a249b16f24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2092 entries, 0 to 2091\n","Data columns (total 4 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   post     2092 non-null   object\n"," 1   context  2092 non-null   object\n"," 2   text     2092 non-null   object\n"," 3   label    2092 non-null   int64 \n","dtypes: int64(1), object(3)\n","memory usage: 65.5+ KB\n"]}]},{"cell_type":"code","source":["df.to_pickle(\"test_hierarchial.pkl\")"],"metadata":{"id":"oZ7jOkdeq4P1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test = pd.read_pickle(\"test_hierarchial.pkl\")"],"metadata":{"id":"eiqaw137rAlQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","epochs = 4 \n","\n","print(\"Testing....\")\n","for epoch in range(epochs):\n","    predictions = []\n","    labels = []\n","    print(\"==========Epochs:{}===========\".format(epoch))  \n","\n","    for post, context,text, label in zip(test[\"post\"], test[\"context\"], test[\"text\"], test[\"label\"]):\n","\n","      logits = model.forward(post, context,text, label)\n","\n","      y_pred = torch.argmax(logits, dim = -1).item()\n","\n","      predictions.append(y_pred)\n","      labels.append(label)\n","    print(\"Accuracy: {}\".format(accuracy_score(predictions, labels)))"],"metadata":{"id":"Z6GQh_0walEC","colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"status":"error","timestamp":1641611624594,"user_tz":-345,"elapsed":44991,"user":{"displayName":"Kamal Shrestha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRmbrhanuWLNu07Db5etQmkaTAbYTjqIM3oCin=s64","userId":"06925189110392645592"}},"outputId":"a0509f48-0b19-4686-f051-f2d31758660a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epochs:0\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-d6234fcb0e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-afdc25334c1a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, post, context, text, label, only_post, post_context)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_representations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_representations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_representations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mcontext_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-afdc25334c1a>\u001b[0m in \u001b[0;36mbert_representations\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbert_representations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2368\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2370\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[""],"metadata":{"id":"asAod3X0vKLU"},"execution_count":null,"outputs":[]}]}