{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_pickle(\"p1_codemix_flat.pkl\")\n",
    "test = pd.read_pickle(\"p1_codemix_flat_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_pickle(\"XLMR_preds_1e-4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for i in range(len(preds)):\n",
    "        if preds[i]==1:\n",
    "            index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.iloc[index]\n",
    "train = train.loc[train[\"label\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 16:46:14.901980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-18 16:46:14.902019: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distribution = {}\n",
    "count = 0\n",
    "for text in train[\"text\"]:\n",
    "    text1 = NER(text)\n",
    "    count=count+len(text1)\n",
    "    for word in text1.ents:\n",
    "        if word.label_ not in train_distribution:\n",
    "            train_distribution[word.label_]=1\n",
    "        else:\n",
    "            train_distribution[word.label_] = train_distribution[word.label_]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_distribution = {}\n",
    "count = 0\n",
    "for text in test[\"text\"]:\n",
    "    text1 = NER(text)\n",
    "    count=count+len(text1)\n",
    "    for word in text1.ents:\n",
    "        if word.label_ not in test_distribution:\n",
    "            test_distribution[word.label_]=1\n",
    "        else:\n",
    "            test_distribution[word.label_] = test_distribution[word.label_]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "train_distribution_value_sorted = OrderedDict(sorted(train_distribution.items(), key=lambda t: t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys = list(train_distribution.keys())\n",
    "test_keys = list(test_distribution.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_to_train = {}\n",
    "\n",
    "for key, value in train_distribution_value_sorted.items():\n",
    "    if key not in test_keys:\n",
    "        test_acc_to_train[key]=0\n",
    "    else:\n",
    "        test_acc_to_train[key] = test_distribution[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_distribution_value_sorted = OrderedDict(sorted(test_distribution.items(), key=lambda t: t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_distribution_key_sorted = {key: value for key, value in sorted(train_distribution.items())}\n",
    "\n",
    "# test_distribution_key_sorted = {key: value for key, value in sorted(test_distribution.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3503599174.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1337728/3503599174.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    plot.legend(loc=2, prop={'size': 6})plt.xlabel(\"Named Entities\")\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_distribution_value_sorted.keys(), train_distribution_value_sorted.values(), color=\"r\", label = \"HOF labelled examples from Train Data\") \n",
    "plt.plot(test_acc_to_train.keys(), test_acc_to_train.values(), color=\"blue\", label=\"HOF predicted (using proposed model) Test Data Examples\") \n",
    "plt.xticks(rotation=90)\n",
    "plot.legend(loc=2, prop={'size': 6})\n",
    "plt.xlabel(\"Named Entities\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"namedentity.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_keys = list(train_distribution.keys())\n",
    "# test_keys = list(test_distribution.keys())\n",
    "\n",
    "# for key in train_keys:\n",
    "#     if key not in test_keys:\n",
    "#         test_distribution[key]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "x = np.array(list(train_distribution_value_sorted.values()))\n",
    "y = np.array(list(test_acc_to_train.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9633922250780449, 1.445731346165369e-10)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.pearsonr(x, y)\n",
    "# Correlation, P-Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.9498221118264386, pvalue=1.7255700879492758e-09)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.spearmanr(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.841133386279524, pvalue=1.3884655823390914e-06)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.kendalltau(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "820250bceef0ad969593e947a9fb574bdce77274dbf9ae33ffd3f4e00efdde57"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aditi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
